{
 "metadata": {
  "name": "",
  "signature": "sha256:a9a68a347bad4083e9ff6b362457123c6aeeffff7f819bd4dc0209d47115e386"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Segment Image Script"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "\"\"\"\n",
      "Created on Tue Jun 24 14:19:11 2014\n",
      "\n",
      "@author: stuart\n",
      "\"\"\"\n",
      "\n",
      "%matplotlib inline "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from math import ceil\n",
      "from math import pi\n",
      "import numpy as np\n",
      "import os\n",
      "import SimpleITK as sitk\n",
      "import pylab as p\n",
      "import sklearn.mixture as sk\n",
      "import multiprocessing as mp\n",
      "from IPython import parallel\n",
      "import scipy.stats as ss\n",
      "import scipy.ndimage.morphology as snd\n",
      "from scipy.ndimage import gaussian_filter\n",
      "import time\n",
      "import itertools as i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#file directory setup\n",
      "read_dir = os.path.join(os.path.expanduser(\"~\"), \"weirepo/share/ALL_CASES\")\n",
      "write_dir = os.path.join(os.path.expanduser(\"~\"), \"weirepo/share/heartExtractions\")\n",
      "raw_file_name = \"rw.nii.gz\"\n",
      "\n",
      "print \"intitalized \""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "intitalized \n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################################################\n",
      "# Functions\n",
      "####################################################################################\n",
      "# File management\n",
      "def read_image_files(files):\n",
      "    \"\"\"Read list of image files and returns list of images\"\"\"\n",
      "    out_images = []\n",
      "    if type(files) == list:\n",
      "        for file_ in files:\n",
      "            image = sitk.ReadImage(file_)\n",
      "            image_data = sitk.GetArrayFromImage(image)\n",
      "            out_images.append(image_data)\n",
      "    return out_images"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_image_files(in_data, out_files, images_metadata=None):\n",
      "    \"\"\"Write in_data to file_names and copy meta data images_metadata\"\"\"\n",
      "    if type(out_files) == list:\n",
      "        if len(in_data) != len(out_files) and type(in_data) == list:\n",
      "            print \"in_data and out_files are different lengths\"\n",
      "        n = len(out_files)\n",
      "        for i in range(n):\n",
      "            out_img = sitk.GetImageFromArray(np.int16(in_data[i]))\n",
      "            if images_metadata != None:\n",
      "                out_img.CopyInformation(images_metadata[i])\n",
      "            sitk.WriteImage(out_img, out_files[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_multivariate_overlay(in_data, mean=[150, 235, 275], var=1500):\n",
      "    # create multivariate distributions\n",
      "    shape_ = in_data.shape\n",
      "    mean_1 = [mean[0]-25, mean[1]-40, mean[2]]\n",
      "    mean_2 = [mean[0]-50, mean[1], mean[2] + 40]\n",
      "    cov = [[var, 0, 0], [0, var, 0], [0, 0, var]]\n",
      "    mv_norm_0 = ss.multivariate_normal(mean=mean, cov=cov)\n",
      "    mv_norm_1 = ss.multivariate_normal(mean=mean_1, cov=cov)\n",
      "    mv_norm_2 = ss.multivariate_normal(mean=mean_2, cov=cov)\n",
      "    \n",
      "    # create distribution test values\n",
      "    ones_indicies_split = np.dstack(np.where(np.ones(shape_) == 1))\n",
      "    \n",
      "    # combine distributions\n",
      "    dist = np.reshape(mv_norm_0.pdf(ones_indicies_split) + mv_norm_1.pdf(ones_indicies_split) + mv_norm_2.pdf(ones_indicies_split), shape_)\n",
      "    return dist\n",
      "  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "          \n",
      "# Image manipulation\n",
      "def get_multivariate(dist, circum):\n",
      "    # combine image data with distribution\n",
      "    return dist * circum ** 2\n",
      "\n",
      "def get_data_mean(in_data, dist, circum, mask=None):\n",
      "    if mask is None:\n",
      "        return int(np.mean(in_data[np.int16(dist * circum**2) > 1])), int(np.std(in_data[np.int16(dist * circum**2) > 1]))\n",
      "    else:\n",
      "        return int(np.mean(in_data[np.logical_and(np.int16(dist * circum**2) > 1, mask)])), int(np.std(in_data[np.logical_and(np.int16(dist * circum**2) > 1, mask)]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_heart_file_names(image):\n",
      "    \"\"\"\n",
      "        generate all the files used in pipeline\n",
      "    \"\"\"\n",
      "    #heart file names\n",
      "    base = image.replace(\".nii.gz\", \"\")\n",
      "    \n",
      "    raw_file_name = image\n",
      "    filtered_file_name = base + \"_filtered.nii.gz\"\n",
      "    bin_filtered_file_name = base + \"_bin_filtered.nii.gz\"\n",
      "    raw_filtered_weighted_file_name = base + \"_raw_filtered_weighted.nii.gz\"\n",
      "    seg_file_name = base + \"_seg.nii.gz\"\n",
      "    bin_heart_file_name = base + \"_bin_heart.nii.gz\"\n",
      "    bin_chamber_file_name = base + \"_bin_chamber.nii.gz\"\n",
      "    temp_file_name = \"temp.nii.gz\"\n",
      "    \n",
      "    raw_file = os.path.join(read_dir, raw_file_name) #raw file\n",
      "    raw_filtered_file = os.path.join(write_dir, filtered_file_name) #preprocessed file\n",
      "    raw_filtered_weighted_file = os.path.join(write_dir, raw_filtered_weighted_file_name) #raw filtered statistically transformed for heart segmentation file\n",
      "    bin_filtered_file = os.path.join(write_dir, bin_filtered_file_name) #bin filtered and blurred for heart segmentation file\n",
      "    seg_file = os.path.join(write_dir, seg_file_name) #gmm heart segmentation file    \n",
      "    bin_heart_file = os.path.join(write_dir, bin_heart_file_name) #heart binary file\n",
      "    bin_chamber_file = os.path.join(write_dir, bin_chamber_file_name) #bin Chamber file\n",
      "    temp_file = os.path.join(write_dir, temp_file_name) #temp file\n",
      "    \n",
      "    files = [raw_file, raw_filtered_file, raw_filtered_weighted_file, bin_filtered_file, seg_file, bin_heart_file, bin_chamber_file, temp_file]\n",
      "    return files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_center(data):\n",
      "    shape_ = data.shape\n",
      "    temp_cond = np.where(data[shape_[0] / 4 : shape_[0] * 4 / 5, :, shape_[2] / 2] >= 0)\n",
      "    y = (shape_[1] - np.min(temp_cond[1])) * 1 / 2 + 10\n",
      "    x = shape_[2] / 2 + 5\n",
      "    z = shape_[0] * 5 / 11\n",
      "    return [z, y, x]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_circum(data):\n",
      "    shape_ = data.shape\n",
      "    return shape_[0] * shape_[1] * shape_[2] / 55555 # result usually ~ 1500  (picked because it works)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def preprocess_filter(data, mean, mean_intensity, std_intensity): \n",
      "    filtered_data = data - mean_intensity #center data\n",
      "    bin_data = (filtered_data > 0) * 1 #create bin of data based off mean intensity\n",
      "    factor = std_intensity * 3\n",
      "            #prob_filtered_data = (2 * pi * std_intensity) ** (-1 / 2) * np.exp(((filtered_data * bin_data) - std_intensity * 1.5) ** 2 / (-2 * std_intensity ** 2))\n",
      "            #scalar = std_intensity * 1.5 / np.max(prob_filtered_data)\n",
      "            #scaled_filtered_data = prob_filtered_data * scalar\n",
      "    scaled_filtered_data = np.ceil(np.exp((- 5 * factor) / (filtered_data * bin_data + 1)) * (factor)) #scale down outlier data\n",
      "            #filtered_data[filtered_data > factor] = 0\n",
      "    filtered_data = np.int16(filtered_data * (bin_data == 0) + (scaled_filtered_data)) #basically scale down data that is larger than mean\n",
      "    filtered_data = (np.abs(filtered_data) * -1) + mean_intensity #shift data back to starting position\n",
      "    boundry = mean_intensity - factor\n",
      "    filtered_data[filtered_data < boundry] = boundry #remove all extreme data points\n",
      "    return filtered_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# notify user\n",
      "def alert(text=\"Hey\"):\n",
      "    os.system('espeak \"%s\"' % text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# segmentation pipeline\n",
      "def chamber_segmentation_pipeline(image, seg=False, mean_intensity_about_heart=164, std_intensity_about_heart=150):\n",
      "\n",
      "    #try:\n",
      "    raw_file, raw_filtered_file, raw_filtered_weighted_file, bin_filtered_file, seg_file, bin_heart_file, bin_chamber_file, temp_file = get_heart_file_names(image)\n",
      "    #print raw_file, raw_filtered_file, raw_filtered_weighted_file, bin_filtered_file, seg_file, bin_heart_file, bin_chamber_file, temp_file\n",
      "    #######################################################################\n",
      "    # filter image for heart segmentation ~10-30``\n",
      "    #######################################################################\n",
      "    #read in raw data\n",
      "    data = (read_image_files([raw_file]))[0]\n",
      "    cp_img = sitk.ReadImage(raw_file)\n",
      "    if(not seg):\n",
      "        alert(\"Preprocesssing\")\n",
      "        circum = get_circum(data)\n",
      "        heart_center = get_center(data)\n",
      "        print \"   circum = %r\" % circum\n",
      "        print \"   center of heart = %r\" % heart_center\n",
      "        mv_overlay = get_multivariate_overlay(data, heart_center, circum)\n",
      "        if mean_intensity_about_heart == 0:\n",
      "            mean_intensity_about_heart, std_intensity_about_heart = get_data_mean(data, mv_overlay, circum)\n",
      "        print \"   Mean of intensity about heart = %r\" % mean_intensity_about_heart\n",
      "        print \"   STD of intensity about heart = %r\" % std_intensity_about_heart\n",
      "\n",
      "        #preprocess filter data\n",
      "        filtered_data = preprocess_filter(data, heart_center, mean_intensity_about_heart, std_intensity_about_heart)\n",
      "\n",
      "        ## blur data slightly\n",
      "        #filtered_data = gaussian_filter(filtered_data, sigma=.5)\n",
      "\n",
      "        ##superimpose multivariate distribution upon raw image\n",
      "        mv_dist = np.int16(get_multivariate(mv_overlay, circum) * std_intensity_about_heart)\n",
      "        boundry = int(mean_intensity_about_heart - std_intensity_about_heart * 2.5)\n",
      "        print \"   boundry = %s\" % boundry\n",
      "        mv_data = filtered_data + ((filtered_data > boundry) * mv_dist)\n",
      "        alert(\"Cleaning Data\")\n",
      "\n",
      "        #blur mv data\n",
      "        mv_blur_data = gaussian_filter(mv_data, .5)\n",
      "\n",
      "        ##get new data mean and std\n",
      "        mean_intensity_about_heart, std_intensity_about_heart = get_data_mean(mv_blur_data, mv_overlay, circum, (mv_blur_data > 0))\n",
      "        print \"   Mean of intensity about heart final = %r\" % mean_intensity_about_heart\n",
      "        print \"    STD of intensity about heart final = %r\" % std_intensity_about_heart\n",
      "        \n",
      "        #filter data into binary based of bounds\n",
      "        lower_bound = mean_intensity_about_heart - (std_intensity_about_heart * 2.5) #mean_intensity_about_heart - 50\n",
      "        print \"   filter lower bound = %s\" % lower_bound\n",
      "        mv_blur_bin_data = (mv_blur_data >= lower_bound)\n",
      "        mv_blur_bin_data = np.int16(mv_blur_bin_data * 1)\n",
      "\n",
      "        #expand bin volume slightly\n",
      "        mv_blur_bin_data = (mv_blur_bin_data <= 0) * 1\n",
      "        mv_blur_bin_data = gaussian_filter(mv_blur_bin_data, sigma=.2)\n",
      "        mv_blur_bin_data = np.int16((mv_blur_bin_data <= 0) * 1)\n",
      "\n",
      "        #filter data raw\n",
      "        mv_blur_raw_data = mv_blur_data\n",
      "        mv_blur_raw_data[mv_blur_raw_data <= lower_bound] = lower_bound\n",
      "        mv_blur_raw_data = mv_blur_raw_data - lower_bound\n",
      "\n",
      "        #temporary option\n",
      "        #mv_blur_raw_data = mv_blur_bin_data * (mv_blur_bin_data + mv_dist)\n",
      "\n",
      "        #write transformed images\n",
      "        data_ = [filtered_data, mv_blur_bin_data, mv_blur_raw_data]\n",
      "        files_ = [raw_filtered_file, bin_filtered_file, raw_filtered_weighted_file]\n",
      "        copy_ = [cp_img] * 3\n",
      "        write_image_files(data_, files_, copy_)\n",
      "        del data, mv_overlay, filtered_data, mv_data, mv_blur_data, mv_blur_bin_data, mv_blur_raw_data, data_, mv_dist\n",
      "        #alert(\"error\");error\n",
      "\n",
      "    # C version of the GMM ~5`\n",
      "    print \"   start GMM\"\n",
      "    alert(\"starting Gaussian Mixture Model\")\n",
      "    function_ = \"~/packages/ucair-master/build/gmm\"\n",
      "    other_arguments = \"--ncomp 2 --mean %r %r --sigma 10 %r --prop 0.4 0.6  --maxit 30\" % ((0 + 20), int(mean_intensity_about_heart + std_intensity_about_heart), int(std_intensity_about_heart))\n",
      "    command = \"%s --input %s --seg %s --mask %s %s\" % (function_, raw_filtered_weighted_file, seg_file, bin_filtered_file, other_arguments)\n",
      "    print \"   %s\" % command\n",
      "    os.popen(command).read()\n",
      "    print \"   finished GMM\"\n",
      "    \n",
      "    #try:    \n",
      "    alert(\"segmenting heart\")\n",
      "    ############################################################\n",
      "    # seperate heart from noise and clean up\n",
      "    ############################################################\n",
      "    #read segmenation file\n",
      "    seg_data = (read_image_files([seg_file]))[0]\n",
      "    filtered_data = (read_image_files([raw_filtered_file]))[0]\n",
      "    temp_data = seg_data\n",
      "\n",
      "    #seperate components: motivation-to help seperate bone/tissue not removed by the previous steps\n",
      "    component = 3\n",
      "    s = seg_data.shape\n",
      "    n = s[0] * s[1] * s[2]\n",
      "    m = np.sum(seg_data==1)\n",
      "    threshold = component - 1\n",
      "    if (n / m) < 10:  #if we have a large ratio then we will have done a good job up to now homing in on only the heart\n",
      "        threshold = component + 2\n",
      "    seg_data = gaussian_filter(seg_data * component, sigma=2)\n",
      "    seg_data = np.ceil(seg_data)\n",
      "    seg_data[seg_data <= threshold] = 0\n",
      "    seg_data[seg_data > threshold] = 1\n",
      "    temp_data = seg_data\n",
      "    temp_img = sitk.GetImageFromArray(np.int16(seg_data))\n",
      "\n",
      "    # do the connected component\n",
      "    temp_img = sitk.ConnectedComponent(temp_img)\n",
      "\n",
      "    # remove small components.\n",
      "    temp_img = sitk.RelabelComponent(temp_img, 100000)\n",
      "    \n",
      "    # closing\n",
      "    temp_img = sitk.BinaryMorphologicalClosing(temp_img, 2)\n",
      "\n",
      "    # fill holes\n",
      "    h_bin_data = sitk.GetArrayFromImage(temp_img)\n",
      "    h_bin_data = snd.binary_fill_holes(h_bin_data).astype(np.int16)\n",
      "\n",
      "    # expand borders to make up for lost information\n",
      "    h_bin_data = (h_bin_data <= 0) * 1\n",
      "    h_bin_data = gaussian_filter(h_bin_data, sigma=threshold/3.0)\n",
      "    h_bin_data = np.int16((h_bin_data <= 0) * 1)\n",
      "\n",
      "    ####################################################\n",
      "    # segment chambers of heart\n",
      "    ####################################################\n",
      "    # output the raw heart image\n",
      "#     #data[data==0] = 1\n",
      "#     alert(\"segmenting chambers\")\n",
      "#     data = filtered_data\n",
      "#     raw_heart_data_mean = np.mean(data[h_bin_data > 0])\n",
      "#     raw_heart_data = h_bin_data * data\n",
      "#     raw_heart_data[raw_heart_data==0] = -2000\n",
      "\n",
      "#     #blur raw heart data\n",
      "#     raw_heart_data = gaussian_filter(raw_heart_data, 1)\n",
      "#     heart_data = h_bin_data * raw_heart_data\n",
      "\n",
      "#     #filter binarize data\n",
      "#     threshold = raw_heart_data_mean\n",
      "#     bin_chamber_data = heart_data\n",
      "#     bin_chamber_data[bin_chamber_data < threshold] = 0\n",
      "#     bin_chamber_data[bin_chamber_data >= threshold] = 1\n",
      "\n",
      "#     #fill holes and select largest component\n",
      "#     bin_chamber_data = snd.binary_fill_holes(bin_chamber_data).astype(np.int16)\n",
      "#     temp_img = sitk.GetImageFromArray(bin_chamber_data)\n",
      "#     temp_img = sitk.ConnectedComponent(temp_img)\n",
      "#     temp_img = sitk.RelabelComponent(temp_img, 100000)\n",
      "#     temp_img = sitk.BinaryMorphologicalClosing(temp_img, 5)\n",
      "#     bin_chamber_data = sitk.GetArrayFromImage(temp_img)\n",
      "\n",
      "    #write transformed images\n",
      "    bin_chamber_data = h_bin_data\n",
      "    data_ = [h_bin_data, bin_chamber_data, temp_data]\n",
      "    files_ = [bin_heart_file, bin_chamber_file, temp_file]\n",
      "    copy_ = [cp_img] * 3\n",
      "    write_image_files(data_, files_, copy_)\n",
      "        \n",
      "    return \"Completed!\"\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Heart Segmentation\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#image file list\n",
      "#images = sorted([file_ for file_ in os.listdir(read_dir)])\n",
      "#images = [\"PE000000.nii.gz\", \"PE000003.nii.gz\",  \"PE000005.nii.gz\",  \"PE000013.nii.gz\",  \"PE000002.nii.gz\",  \"PE000004.nii.gz\",  \"PE000007.nii.gz\",  \"PE000900.nii.gz\"]\n",
      "images = [\"PE000000.nii.gz\"]\n",
      "for image in images:\n",
      "    print \"*\" * 41\n",
      "    print \"*** working on image: %s ***\" % image\n",
      "    start = time.time()\n",
      "    val = chamber_segmentation_pipeline(image, False, 0, 0)\n",
      "    print \"   lapse = %.2f minutes\" % ((time.time() - start) / 60)\n",
      "    print val\n",
      "    print \"*\" * 41\n",
      "    alert(\"next\")\n",
      "\n",
      "alert(\"finished\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "*****************************************\n",
        "*** working on image: PE000000.nii.gz ***\n",
        "   circum = 1665"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   center of heart = [160, 241, 261]\n",
        "   Mean of intensity about heart = 202"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   STD of intensity about heart = 182\n",
        "   boundry = -253"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   Mean of intensity about heart final = 694"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    STD of intensity about heart final = 210\n",
        "   filter lower bound = 169.0\n",
        "   start GMM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   ~/packages/ucair-master/build/gmm --input /home/stuart/weirepo/share/heartExtractions/PE000000_raw_filtered_weighted.nii.gz --seg /home/stuart/weirepo/share/heartExtractions/PE000000_seg.nii.gz --mask /home/stuart/weirepo/share/heartExtractions/PE000000_bin_filtered.nii.gz --ncomp 2 --mean 20 904 --sigma 10 210 --prop 0.4 0.6  --maxit 30"
       ]
      }
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Manual vs Automatic Comparison"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_segmentation_accuracy(m_file, a_file, a_file_all):\n",
      "    #automatic_seg_file = os.path.join(read_dir, image + \"_bin_heart.nii.gz\")\n",
      "    m_data = (read_image_files([m_file]))[0]\n",
      "    a_data = (read_image_files([a_file]))[0]\n",
      "    a_data_all = (read_image_files([a_file_all]))[0]\n",
      "\n",
      "    m_total = np.sum(m_data) * 1.0\n",
      "    a_total_all = np.sum(a_data_all) * 1.0\n",
      "    a_total = np.sum(a_data) * 1.0\n",
      "    total = m_data.size * 1.0\n",
      "    union_all = np.logical_or(m_data != 0, a_data_all != 0)\n",
      "    union = np.logical_or(m_data != 0, a_data != 0)\n",
      "    union_all_total = np.sum(union_all) * 1.0\n",
      "    union_total = np.sum(union) * 1.0\n",
      "\n",
      "    print \"   Percent removed from automatic segmentation: %.5f\" % (a_total / a_total_all)\n",
      "    print \"   Total points (manual): %r\" % m_total\n",
      "    print \"   Total points (automatic, pre): %r\" % a_total_all\n",
      "    print \"   Total points (automatic, post): %r\" % a_total\n",
      "    print \"   Total points: %r\" % total\n",
      "    print \"   Total unioned points (pre): %r\" % union_all_total\n",
      "    print \"   Total unioned points (post): %r\" % union_total\n",
      "\n",
      "    points_same_all_total = np.sum(m_data == a_data_all) * 1.0\n",
      "    points_same_all_union_total = np.sum(np.logical_and(m_data != 0, a_data_all != 0)) * 1.0\n",
      "    \n",
      "    points_same_total = np.sum(m_data == a_data) * 1.0\n",
      "    points_same_union_total = np.sum(np.logical_and(m_data != 0, a_data != 0)) * 1.0\n",
      "    \n",
      "    print \"   Accuracy (pre-segmentation, total): %.5f\" % (points_same_all_total / total)\n",
      "    print \"   Accuracy (pre-segmentation, union): %.5f\" % (points_same_all_union_total /  union_all_total)\n",
      "    print \"   Accuracy (post-segmentation, total): %.5f\" % (points_same_total / total)\n",
      "    print \"   Accuracy (post-segmentation, union): %.5f\" % (points_same_union_total / union_total)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#images = [\"PE000000.nii.gz\", \"PE000003.nii.gz\",  \"PE000005.nii.gz\",  \"PE000013.nii.gz\",  \"PE000002.nii.gz\",  \"PE000004.nii.gz\",  \"PE000007.nii.gz\",  \"PE000900.nii.gz\"]\n",
      "images = [\"PE000000.nii.gz\"]\n",
      "for image in images:\n",
      "    print \"*\" * 30\n",
      "    print \"********** %s **********\" % image\n",
      "    read_dir_m = os.path.join(os.path.expanduser(\"~\"), \"weirepo/share/manual_heart_seg\")\n",
      "    read_dir_a = os.path.join(os.path.expanduser(\"~\"), \"weirepo/share/heartExtractions\")\n",
      "\n",
      "    manual_seg_file = os.path.join(read_dir_m, image + \".nii.gz\")\n",
      "    automatic_seg_file = os.path.join(read_dir_a, image + \"_heart_segmented.nii.gz\")\n",
      "    automatic_all_seg_file = os.path.join(read_dir_a, image + \"_bin_heart.nii.gz\")\n",
      "    \n",
      "    compute_segmentation_accuracy(manual_seg_file, automatic_seg_file, automatic_all_seg_file)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}